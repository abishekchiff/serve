{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Captum Visual Insights for BERT Seq Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook helps you to get started with the Captum Insights. Now that we have gotten the response from the Torchserve API for Captum Explanations, it's important to understand the word importance and their attributions.The example covered here is from the Hugginface Transformers pre-trained model used in Torchserve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import captum\n",
    "from captum.attr import visualization as viz\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to map the label with the classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label_mapping(mapping_file_path):\n",
    "    \"\"\"\n",
    "    Load a JSON mapping { class ID -> friendly class name }.\n",
    "    Used in BaseHandler.\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(mapping_file_path):\n",
    "        logging.info('Missing the index_to_name.json file. Inference output will not include class name.')\n",
    "        return None\n",
    "\n",
    "    with open(mapping_file_path) as f:\n",
    "        mapping = json.load(f)\n",
    "    if not isinstance(mapping, dict):\n",
    "        raise Exception('index_to_name mapping should be in \"class\":\"label\" json format')\n",
    "\n",
    "    # Older examples had a different syntax than others. This code accommodates those.\n",
    "    if 'object_type_names' in mapping and isinstance(mapping['object_type_names'], list):\n",
    "        mapping = {str(k): v for k, v in enumerate(mapping['object_type_names'])}\n",
    "        return mapping\n",
    "\n",
    "    for key, value in mapping.items():\n",
    "        new_value = value\n",
    "        if isinstance(new_value, list):\n",
    "            new_value = value[-1]\n",
    "        if not isinstance(new_value, str):\n",
    "            raise Exception('labels in index_to_name must be either str or [str]')\n",
    "        mapping[key] = new_value\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the Response JSON Object and load the attributions, word importances and delta key-value pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file=open('./bert_response.json', 'r')\n",
    "input_json = json.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributions = input_json['explanations'][0]['importances']\n",
    "words = input_json['explanations'][0]['words']\n",
    "delta = input_json['explanations'][0]['delta']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualization purpose using Captum, the attributions and delta parameters should be in the form of Torch Tensors. Please note that the Predictions is returned from the Inference Request.The predicted response should be converted to a torch tensor as the parameter is passed as arguments to the captum visualizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#curl request to make a Prediction Request\n",
    "!curl -H \"Content-Type: application/json\" --data @examples/Huggingface_Transformers/bert_ts.json http://127.0.0.1:8080/predictions/bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the predictions value from the Inference Request and place it here.\n",
    "predictions = [ \n",
    "         -0.05393758416175842,\n",
    "          0.3400498330593109\n",
    "        ]\n",
    "#convert predictions to a torch tensor and take the argmax value of it\n",
    "predictions2 = torch.tensor(predictions)\n",
    "predictions2 = torch.argmax(predictions2)\n",
    "\n",
    "#Mapping the class to the labels for the BERT Seq Classification Model\n",
    "mapping = load_label_mapping(\"index_to_name_bert.json\")\n",
    "true_label = 'Accepted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ind = torch.argmax(predictions2)\n",
    "label = mapping[str(pred_ind.item())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a word tokenizer using the Hugginface Transformer's Auto tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(os.path.join(\".\", \"vocab.*\")):\n",
    "            tokenizer = AutoTokenizer.from_pretrained(\n",
    "                \"bert-base-uncased\",\n",
    "                do_lower_case= True,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_ids = tokenizer.convert_tokens_to_ids(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Visualization Data Record method from Captum's Visualization toolkit to render the visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = viz.VisualizationDataRecord(\n",
    "                        attributions2,\n",
    "                        predictions2,\n",
    "                        label,\n",
    "                        true_label,\n",
    "                        label,\n",
    "                        attributions2.sum(),       \n",
    "                        words,\n",
    "                        delta2)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table width: 100%><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Accepted</b></text></td><td><text style=\"padding-right:2em\"><b>Not Accepted (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>Not Accepted</b></text></td><td><text style=\"padding-right:2em\"><b>-0.04</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> recent                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> climate                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> change                    </font></mark><mark style=\"background-color: hsl(120, 75%, 76%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> across                    </font></mark><mark style=\"background-color: hsl(0, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> world                    </font></mark><mark style=\"background-color: hsl(120, 75%, 76%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> impact                    </font></mark><mark style=\"background-color: hsl(0, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ing                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> negatively                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "viz.visualize_text([result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
